---
layout: post
title: StyleGAN
date: 2021-06-07
category: GAN
use_math: true
---


## A Style-Based Generator Architecture for Generative Adversarial Networks

오늘은 NVDIA에서 발표한 styleGAN을 살펴볼 것이다. 그에 앞서 StyleGAN의 baseline이 되는 PGGAN을 간단하게 살펴보도록 한다.

### Progressive Growing of GANs for Improved Quality, Stability, and Variation (PGGAN) 

PGGAN은 아주 낮은 화질 (4x4)에서 시작해 점차적으로 더 높은 화질을 만들수 있는 레이어를 쌓아가며 고화질 이미지(1024x1024)를 생성한다.
초반에는 낮은 화질의 이미지에서도 볼 수 있는 기본적인 특징들을 학습해 이미지의 윤곽을 잡아주고, 화질을 높여가며 디테일 한 부분들을 학습해 나가는 것이다. 
이렇게 하면 저화질의 이미지가 고화질 이미지 학습의 토대가 되어 어느 정도의 조건을 제시해주기 때문에 학습이 빨라진다는 장점이 있다. 부전승 느낌..?
하지만 PGGAN은 다른 GAN 모델과 같이 학습의 내부 동작을 사람이 알 수 없기 때문에 생성된 이미지의 구체적인 특징을 조절하는 것을 어렵고, latent space의 속성도 여전히 해석이 어렵다.
그리고 특징들이 얽혀있기 때문에 인풋을 조금 변경하면 여러 특징들에 동시에 영향을 미친다. 
따라서 NVIDA는 generator의 구조를 새롭게 만들어서 이미지 합성 프로세스를 제어하는 styleGAN을 제안한다. 



