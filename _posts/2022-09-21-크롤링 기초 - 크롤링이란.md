---
layout: post
title: 크롤링 기초 - 크롤링이란
date: 2022-09-21
category: Web
use_math: true
---

### 크롤링

예전에는 각 웹 페이지가 있으면 사용자가 그 웹 페이지에 접근하기 위해서는 각 페이지의 도메인을 다 알고 있어야 했다. 그래서 내가 원하는 정보가 어떤 페이지에 있는지 미리 알고 그 페이지의 도메인으로 접근해야 하는 것이다. 

![image](https://user-images.githubusercontent.com/61526722/191630570-9d4a68ec-f38b-43be-8a99-9ebc6ac0f236.png)

크롤링은 검색을 위해서 만들어졌다고 봐도 된다. 구글에서 검색을 하면 검색어에 해당하는 글들을 홈페이지에서 알아서 서버로 가져와 준다. 이렇게 크롤링(WWW 을 자동화해서 탐색)을 수행하는 아이를 크롤러라고 하고, 구글의 검색 엔진을 크롤러 봇이라고 한다. 

웹 크롤러(web crawler)는 조직적, 자동화된 방법으로 월드 와이드 웹을 탐색하는 컴퓨터 프로그램이다. 크롤링은 WWW을 본따는 것이라면 파싱은 조금 더 좁은 범위로 원하는 정보만을 가져오는 것을 말한다. 

### WWW

개발자 도구로 네이버 페이지를 띄워보면 아래와 같이 나온다. Response header는 Request header는 우리가 어떤 것을 요청했는지 보여준다. accept는 사용자가 이 페이지를 XML로 읽기를 원하는지 HTML로 읽기를 원하는지를 정해준다. cookie는 홈페이지에 로그인하면 암호화된 정보가 들어가서 cookie를 알고 있으면 다른 사람이 내 아이디로 로그인이 가능하니 조심해야 한다. referer는 웹이 어디서 왔는지, sec 들은 보안에 관련된 정보들을 정해준다. user agent는 사용자가 어떤 브라우저를 통해서 어떠한 기기를 통해서 접근했는지를 알려주어, 해외에서 접근할 떄 경고를 띄워줄 수 있다. 이렇게 홈페이지에 요청을 보내면 

![image](https://user-images.githubusercontent.com/61526722/191632497-055b1089-b071-4fda-bf10-0a8472417088.png)

![image](https://user-images.githubusercontent.com/61526722/191632537-9f849521-8a90-49db-92f2-c698e8920678.png)
