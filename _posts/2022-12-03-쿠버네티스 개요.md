---
layout: post
title: 쿠버네티스 개요
date: 2022-12-02
category: Kubernetes
---

### 컨테이너 오케스트레이션 시스템

쿠버네티스는 컨테이너 오케스트레이션 시스템중 하나이다. 컨터이너 오케스트레이션 시스템이란 컨테이너의 배포, 관리, 확장, 네트워킹을 자동화하는 기술이다. 

![image](https://user-images.githubusercontent.com/61526722/205427313-a6386270-c810-4024-8332-badb661f70f2.png)

배포를 할때 도커와 도커 컴포즈는 한 대의 머신안에서 여러개의 컨테이너를 관리하기 위한 용도로 사용했다. 컨테이너 오케스트레이션 시스템에서는 여러대의 머신(클러스터) 상에서 여러개의 컨테이너를 관리하는 용도로 사용한다. 즉, **컨테이너 오케스트레이션 시스템**은 여러 머신으로 구성된 클러스터 상에서 컨테이너를 효율적으로 관리하기 위한 시스템이다. 이런 의미에서 운영체제는 하나의 머신에서 프로세스를 효율적으로 관리하기 위한 프로세스 오케스트레이션 시스템이다. 

- Load Balancing
    - overlay network 를 사용 (overlay network: 멀티 노드 환경에서 가상의 네트워크를 만들어 서로 다른 노드에서 동일 네트워크에 있는 것 처럼 네트워킹 하는 기술)
    - 여러 컨테이너로 구성된 서비스에 대해서 트래픽을 분산
- Self Healing
    - 서비스 자동 복구 기능
- Scheduling
    - 서비스가 어떤 노드에 띄워져야 하는지
- Scaling
    - 컨테이너의 개수 조정
- Rollback / Rollout
    - 버전 관리
- Resource Allocation
    - 클러스터는 각기 다른 유휴 자원을 가지고  있음 (CPU, memory, storage, GPU)
    - 어떤 노드에 서비스를 띄워야 필요한 자원들을 사용할 수 있는지
- Service Discovery
    - 어떤 서비스가 다른 서비스와 통신할 때 그 서비스의 위치를 자동으로 발견하는 기능
    - 이를 위해 intenal DNS가 필요 → etcd가 이 역할 수행함
    - 어떤 서비스가 어떤 컨테이너들을 가지고 있고, 해당 컨테이너들의 위치가 어디인지 ID 주소가 무엇인지를 관리해줌
- Configuration Management
    - 어플리케이션을 배포할 때 컨테이너와 그 컨테이너 어플리케이션 설정, 데이터를 주입
- Storage Orchestration
    - 외부 저장소 관리 기능 제공

---

### 쿠버네티스

왜 쿠버네티스를 사용해야 하는가?

- Planet Scale
    - 구글에서 수 십억 개의 컨테이너를 운영할 수 있게 한 원칙 유지
    - 행성 규모로 확장할 수 있는 스케일
- Never Outgrow
    - 다양한 요구사항을 만족할 수 있는 유연함
    - 테스트용 로컬 규모부터 글로벌 서비스 규모까지 유연하게 크기 조정 가능
    - 필요한 기능이 없을 경우 CRD(Custom Resource Definition)를 통한 기능 확장
- Run Anywhere
    - 온프레미스 / 퍼블릭 클라우드 / 하이브리드 환경 어디서나 동작
    - 대부분의 리눅스 환경에서 동작하기 때문에 환경 이동에 제약이 없음

쿠버네티스 주의사항

- 복잡한 클러스터 구성
    - 쿠버네티스 자체가 마이크로서비스 아키텍처로 여러 컴포넌트로 구성된 분산 시스템
    - 각 컴포넌트에 대한 이해 필요
    - 직접 클러스터를 운영하는 것이 어려울 수도 있음 → 매니지드 클러스터 고려 (AWS EKS)
- 방대한 학습량
    - 다른 컨테이너 오케스트레이션 시스템보다 다양한 지식 필요
    - 더 많은 요구사항을 만족하는 만큼, 익혀야 하는 기능도 많음
- 오버 엔지니어링
    - 운영해야 하는 서비스에 적합한가?
    - 쿠버네티스 운영 및 관리에 필요한 인력과 비용이 충분한가?

---

### 쿠버네티스의 배포판 (Kubernetes Distributions)

쿠버네티스는 로컬에서 테스트하기 위한 로컬 배포판과 실제 운영환경에서 사용하기 위한 운영 배포판이 있다. 

![image](https://user-images.githubusercontent.com/61526722/205427321-9771876a-9b49-49ca-98c0-a1dfffaa5453.png)

**로컬 쿠버네티스 배포판**

로컬 쿠버네티스 배포판은 단일 노드에 빠르게 쿠버네티스 구성 및 테스트가 가능하다. 여기서 단인노드는 master node와 worker node 두 가지 기능을 모두 수행한다. 하지만 클라우드 플랫폼에서만 사용 가능한 기능에 제약이 있다. 클라우드에서는 서비스의 로드밸런서 타입, 인그레스를 사용하면 AWS의 ALB나 NLB를 관리할 수 있고, 스토리지클래스와 persistent volume을 사용하면 EBS와 EFS 같은 AWS 스토리지 서비스를 관리할 수 있다. 싱글 노드다 보니 멀티 노드에서만 사용가능한 리소스에도 제약사항이 있다. 모든 쿠버네티스 노드에서 띄워지는 워크로드를 정의하는 Deamonset 리소스, 특정 노드에서만 워크로드가 띄워질 수 있도록 조절하는 옵션인 Affinity/taint/toleration와 같은 노드 셀렉터들이 의미를 상실하게 된다.  

- docker + kubernetes
    - 로컬의 싱글 노드에 쿠버네티스 클러스터가 만들어짐
    - 해당 클러스터에서 기능 테스트
- minikube
    - 드라이버(VM, Virtualbox 등)를 선택하여 쿠버네티스 싱글 노드를 어떤 환경으로 구성할지 선택가능

![image](https://user-images.githubusercontent.com/61526722/205427325-f2c6df7b-dd7a-47e8-8681-65d93d335b1b.png)

**운영용 쿠버네티스 배포판**

운영에서 쿠버네티스를 구축한다면 

- 온프레미스 환경에 자체 서버 위에 구성
    - 서버 관리, 머신 구매, 운영체제 설치, 클러스터 직접 구축
- EC2와 같이 클라우드에서 컴퓨터 리소스를 받아다가 그 위에 클러스터를 직접 구축
    - 머신과 운영체제 관리를 안해도 되지만 클러스터 직접 구축
- 클라우드 플랫폼에서 제공하는 매니지드 클러스트를 이용하는 방법이 있다.

클러스터를 자체 구축할 때는 kops, kubesprary, kubeadm 등의 도구들을 사용한다.  

![image](https://user-images.githubusercontent.com/61526722/205427337-5dc37e44-7f5d-470e-ad32-4f8084ad33d9.png)

---

### 쿠버네티스 클러스터

![image](https://user-images.githubusercontent.com/61526722/205427346-0bc218e0-8869-4e53-b42b-fc2691874d54.png)

쿠버네티스 클러스터는 크게 두가지 영역으로 나뉘어 있다.

- Control Plane (Master Node)
    - 클러스터의 상태를 관리하는 역할 담당
    - 상태 관리 및 명령어 처리
    - 1~n개의 홀수개로 구성
- Node (Worker Node)
    - 어플리케이션 컨테이너가 실행되는 공간
    - container runtime 위에 pod가 실행되는 형태
    - 시스템 컴포넌트로 kubelet, kube-proxy, network addons 등 실행되고 있음

**제어 영역 (Control Plane)**

![image](https://user-images.githubusercontent.com/61526722/205427357-00c13bf7-d897-43a2-ad0b-2773e0217bee.png)

- API Server
    - 클라이언트의 요청을 처리
    - 쿠버네티스 리소스와 클러스터 관리를 위한 API 제공
    - etcd를 데이터 저장소로 사용
- Scheduler
    - API 서버와 통신하면서 노드의 자원 사용 상태(CPU, Memory 등)를 관리하며, 새로운 워크로드(컨테이너)를 어떤 노드에 배포할지 관리
- Controller Manager
    - 각 컨트롤러는 하나의 프로세스들로 띄워짐 → 여러 컨트롤러 프로세스를 관리
    - 각 컨트롤러는 클러스터로부터 특정 리소스(pod, deployment, service, secret 등) 상태의 변화를 감지하여 클러스터에 반영하는 reconcile 과정을 반복 수행
    - etcd에 리소스의 상태가 업데이트 되면 그 업데이트 내용을 클러스터에 반영
    - 쿠버네티스 contoller manager, 클라우드 controller manager로 나뉨 (클라우드 contoller manager: 클라우드 provider 환경에 맞추어 해당 클라우드 provider에 종속적인 기능 수행. 예를 들어 인그레스를 이용하여 AWS ALB이용하거나 storageclass로 EBS 관리)
- etcd
    - 분산 Key - Value 저장소로 클러스터 상태 저장 (상태 관리)
    - 쿠버네티스 클러스트를 백업하고 복구해야 한다면 etcd만 백업하고 복구하면 됨

**노드 (Node)**

노드는 실제로 어플리케이션 컨테이너가 띄워지는 환경이다. 

![image](https://user-images.githubusercontent.com/61526722/205427369-caaf819a-3c26-4ada-ae23-8049233cf003.png)

- kubelet
    - 모든 노드에 설치됨
    - 컨테이너 런타임(Container Runtime)과 통신하며 해당 노드에 띄워지는 컨테이너 라이프사이클 관리
    - API 서버와 통신하며 노드의 리소스 관리 
    (해당 노드가 cpu 몇개, 메모리 몇개를 가지고 있는지 보고)
- CRI (Container Runtime Interface)
    - kubelet이 컨테이너 런타임과 통신할 때 사용되는 인터페이스
    - 쿠버네티스는 Docker, containerd, cri-o 등 다양한 컨테이너 런타임 지원
- kube-proxy
    - 클러스터 상에 오버레이 네트워크 구성
    - 네트워크 프록시 및 내부 로드밸런서 역할 수행

---

### API 리소스

API 리소스는 쿠버네티스가 관리할 수 있는 오브젝트의 종류이다. Pod, Service, ConfigMap, Secret, Node, ServiceAccount, Role 등이 있다. 여기서 오브젝트는 API 리소스를 객체화 시킨것이다. 즉, API 리소스는 오브젝트의 클래스라고 생각하면 되고, 오브젝트는 클래스를 인스턴스화 시킨 것이라고 보면 된다. 예를 들어 pod 리소스를 가지고 grafana pod라는 오브젝트를 만들수도 있고, secret 리소스를 가지고 my-secret이라는 오브젝트를 만들수도 있다. 

![image](https://user-images.githubusercontent.com/61526722/205427380-d02c4727-2374-4ada-9c29-0333981bec0c.png)

```bash
# 현재 쿠버네티스 클러스터가 지원하는 API 리소스 목록 출력
$ kubectl api-resources

# 특정 API 리소스에 대해 간단한 설명 확인
$ kubectl explain pod
```

![image](https://user-images.githubusercontent.com/61526722/205427388-10689f2d-2d39-4850-840f-e7eebc03584a.png)

![image](https://user-images.githubusercontent.com/61526722/205427395-cd5f5070-bd5b-4d0a-87e3-6c8017e25425.png)

**메니페스트 파일**

각각의 API 리소스마다 각기 다른 필드값들을 가지고 있다. 쿠버네티스는 오브젝트를 YAML 파일 기반 매니페스트 파일로 관리한다. YAML 파일은 아래와 같은 네가지 루트 키들이 있다.

- apiVersion
    - 오브젝트가 어떤 API 그룹에 속하고 API 버전이 몇인가?
- kind
    - 오브젝트가 어떤 API 리소스인가?
- metadata
    - 오브젝트를 식별하기 위한 정보(이름, 네임스페이스, 레이블 등)
    - 모든 쿠버네티스 오브젝트는 Labels과 Annotations 메타데이터를 가질 수 있음. 문자열(String) 형식의 Key - Value 데이터를 기록
        - Labels
            - 오브젝트를 식별하기 위한 목적
            - 검색 / 분류 / 필터링 등의 목적으로 사용
            - 쿠버네티스 내부 여러 기능에서 Label Selector 기능 제공
        - Annotations
            - 식별이 아닌 다른 목적으로 사용
            - 보통 쿠버네티스의 애드온이 해당 오브젝트를 어떻게 처리할지 결정하기 위한 설정 용도로 사용
            - log agent 애드온을 사용할 때 로그 수집을 어떻게 할지 annotation으로 지정 가능
- spec
    - 오브젝트가 가지고자 하는 데이터는?
    - API 리소스에 따라 spec 대신 data, rules, subjects 등 다른 속성 사용
    data는 configmap, secret rules는 role에서 사용

---

### kubectl

- 명령형 (Imperative)
    - 수행하고자 하는 액션을 지시
    - 적은 리소스에 대해서 빠르게 처리 가능
    - 여러 명령어를 알아야 함
- 선언형 (Declarative)
    - 도달하고자 하는 상태(Desired State)를 선언
    - 코드로 관리 가능 -> GitOps 활용 가능
        - 변경사항에 대한 감사(Audit) 용이
        - 코드리뷰를 통한 협업
    - 멱등성 보장 (apply)
        - 한번 실행하든 두번 실행하든 동일한 결과를 얻음
    - 많은 리소스에 대해서도 매니페스트 관리 방법에 따라 빠르게 처리 가능
    - 알아야 할 명령어 수가 적음

**kubectl 명령형 명령어**

```bash
# ubuntu:focal 이미지로 ubuntu 파드 생성
$ kubectl run -i -t ubuntu --image=ubuntu:focal bash

# grafana Deployment 오브젝트에 대해 NodePort 타입의 Service 오브젝트 생성 (노드에 포트 개방)
$ kubectl expose deployment grafana --type=NodePort --port=80 --target-port=3000

# frontend Deployment의 www 컨테이너 이미지를 image:v2로 변경
$ kubectl set image deployment/frontend www=image:v2

# frontend Deployment를 리비전 2로 롤백
$ kubectl rollout undo deployment/frontend --to-revision=2
```

**kubectl 선언형 명령어**

```bash
# deployment.yaml에 정의된 쿠버네티스 오브젝트 클러스터에 반영 
$ kubectl apply -f deployment.yaml

# deployment.yaml에 정의된 쿠버네티스 오브젝트 제거
$ kubectl delete -f deployment.yaml

# 현재 디렉토리의 kustomization.yaml 파일을 쿠버네티스 오브젝트 클러스터에 반영
$ kubectl apply -k ./
```
